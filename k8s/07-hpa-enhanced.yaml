# ==========================================
# Enhanced Horizontal Pod Autoscaler with Best Practices
# ==========================================

# Backend HPA - Production-Ready Configuration
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
  namespace: chloromaster
  labels:
    app: backend
    tier: api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend

  # Replica Configuration
  minReplicas: 2 # Always maintain 2 for HA
  maxReplicas: 10 # Scale up to 10 under heavy load

  # Scaling Metrics
  metrics:
    # Primary: CPU-based scaling (most common trigger)
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70 # Scale when avg CPU > 70%

    # Secondary: Memory-based scaling
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80 # Scale when avg memory > 80%

  # Optional: Custom Metrics (uncomment when metrics server is configured)
  # - type: Pods
  #   pods:
  #     metric:
  #       name: http_requests_per_second
  #     target:
  #       type: AverageValue
  #       averageValue: "1000"  # Scale when > 1000 RPS per pod

  # - type: Object
  #   object:
  #     metric:
  #       name: active_connections
  #     describedObject:
  #       apiVersion: v1
  #       kind: Service
  #       name: backend-service
  #     target:
  #       type: Value
  #       value: "5000"  # Scale when service has > 5000 connections

  # Scaling Behavior (Best Practice)
  behavior:
    # Scale Down Behavior - Conservative
    scaleDown:
      stabilizationWindowSeconds: 300 # Wait 5 min before scaling down
      policies:
        # Policy 1: Max 50% reduction per minute
        - type: Percent
          value: 50
          periodSeconds: 60
        # Policy 2: Max 1 pod reduction per minute
        - type: Pods
          value: 1
          periodSeconds: 60
      selectPolicy: Min # Use the more conservative policy

    # Scale Up Behavior - Aggressive
    scaleUp:
      stabilizationWindowSeconds: 60 # Wait 1 min before scaling up
      policies:
        # Policy 1: Max 100% increase per minute
        - type: Percent
          value: 100
          periodSeconds: 60
        # Policy 2: Max 2 pods addition per minute
        - type: Pods
          value: 2
          periodSeconds: 60
      selectPolicy: Max # Use the more aggressive policy

---
# Frontend HPA - Production-Ready Configuration
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-hpa
  namespace: chloromaster
  labels:
    app: frontend
    tier: web
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend

  # Replica Configuration
  minReplicas: 3 # Always maintain 3 for HA and traffic distribution
  maxReplicas: 15 # Scale up to 15 under very heavy load

  # Scaling Metrics
  metrics:
    # Primary: CPU-based scaling
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 60 # Frontend scales more aggressively

    # Secondary: Memory-based scaling
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 70

  # Optional: Custom Metrics (uncomment when configured)
  # - type: Pods
  #   pods:
  #     metric:
  #       name: nginx_active_connections
  #     target:
  #       type: AverageValue
  #       averageValue: "50"  # Scale when > 50 connections per pod

  # - type: Pods
  #   pods:
  #     metric:
  #       name: http_request_duration_seconds
  #     target:
  #       type: AverageValue
  #       averageValue: "0.5"  # Scale when response time > 500ms

  # Scaling Behavior (Optimized for web traffic)
  behavior:
    # Scale Down Behavior - Very Conservative
    scaleDown:
      stabilizationWindowSeconds: 300 # Wait 5 min (traffic can be bursty)
      policies:
        # Policy 1: Max 50% reduction per minute
        - type: Percent
          value: 50
          periodSeconds: 60
        # Policy 2: Max 2 pods reduction per minute
        - type: Pods
          value: 2
          periodSeconds: 60
      selectPolicy: Min # Use more conservative approach

    # Scale Up Behavior - Very Aggressive
    scaleUp:
      stabilizationWindowSeconds: 30 # Quick response to traffic spikes
      policies:
        # Policy 1: Max 100% increase per 30 seconds
        - type: Percent
          value: 100
          periodSeconds: 30
        # Policy 2: Max 3 pods addition per 30 seconds
        - type: Pods
          value: 3
          periodSeconds: 30
      selectPolicy: Max # Use most aggressive policy for web traffic

---
# ==========================================
# Custom Metrics Configuration (Optional)
# Requires Prometheus Adapter or similar
# ==========================================

# Example: Custom metric for backend API requests
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: adapter-config
#   namespace: custom-metrics
# data:
#   config.yaml: |
#     rules:
#     - seriesQuery: 'http_requests_total{namespace="chloromaster",pod=~"backend-.*"}'
#       resources:
#         template: <<.Resource>>
#       name:
#         matches: "^(.*)_total"
#         as: "${1}_per_second"
#       metricsQuery: 'sum(rate(<<.Series>>{<<.LabelMatchers>>}[2m])) by (<<.GroupBy>>)'

---
# ==========================================
# Best Practices Summary
# ==========================================
#
# 1. CPU & Memory Metrics (Standard):
#    ✓ Use CPU as primary metric (most reliable)
#    ✓ Use memory as secondary (prevents OOM)
#    ✓ Set appropriate thresholds (60-80%)
#
# 2. Replica Configuration:
#    ✓ Set minReplicas ≥ 2 for HA
#    ✓ Set maxReplicas based on cluster capacity
#    ✓ Calculate: maxReplicas ≥ (peak_load / target_utilization)
#
# 3. Scaling Behavior:
#    ✓ Scale up fast (handle traffic spikes)
#    ✓ Scale down slow (avoid thrashing)
#    ✓ Use stabilization windows (prevent flapping)
#
# 4. Resource Requests/Limits:
#    ✓ Always set requests (HPA needs them!)
#    ✓ Set limits to prevent resource exhaustion
#    ✓ Ratio: limits = 2x requests (typical)
#
# 5. Custom Metrics (Advanced):
#    ✓ Use for business-specific triggers
#    ✓ Examples: RPS, queue depth, response time
#    ✓ Requires metrics server (Prometheus, etc.)
#
# 6. Testing:
#    ✓ Load test before production
#    ✓ Monitor scaling behavior
#    ✓ Adjust thresholds based on real data
#
# 7. Monitoring:
#    ✓ Watch HPA status: kubectl get hpa -n chloromaster
#    ✓ Check metrics: kubectl top pods -n chloromaster
#    ✓ Review events: kubectl describe hpa <name> -n chloromaster
#
# ==========================================
